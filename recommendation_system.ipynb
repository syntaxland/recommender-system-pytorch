{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Engine with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NvcMQzFckjXd",
    "outputId": "b4424a9f-ffb3-4cfb-fd5b-9fbad8c29b4f"
   },
   "outputs": [],
   "source": [
    "# Data Citation:\n",
    "# F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on \n",
    "# Interactive Intelligent Systems (TiiS) 5, 4: 19:1–19:19. <https://doi.org/10.1145/2827872>\n",
    "\n",
    "# ! curl http://files.grouplens.org/datasets/movielens/ml-latest-small.zip -o ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "68BdqtQikvVE"
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('ml-latest-small.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OmO7jmrpkvZf"
   },
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "import pandas as pd\n",
    "movies_df = pd.read_csv('data/ml-latest-small/movies.csv')\n",
    "ratings_df = pd.read_csv('data/ml-latest-small/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-KRTGaskvdn",
    "outputId": "ec89b4c8-ee99-407c-ce07-8d9ddcf0f0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of movies dataframe are: (9742, 3) \n",
      "The dimensions of ratings dataframe are: (100836, 4)\n"
     ]
    }
   ],
   "source": [
    "print('The dimensions of movies dataframe are:', movies_df.shape,'\\nThe dimensions of ratings dataframe are:', ratings_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "ALPeuAiBk0mM",
    "outputId": "8afc063a-7b73-4cdf-b624-cf36ecfa231a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at movies_df\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "KzPoqkWbk0oh",
    "outputId": "762a17ed-9513-48f8-f1ef-0c1b63347624"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at ratings_df\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TUaWt96k0q7",
    "outputId": "afd13baa-d03e-40c9-9dcf-f8c4cbda08d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 610\n",
      "Number of unique movies: 9724\n",
      "The full rating matrix will have: 5931640 elements.\n",
      "----------\n",
      "Number of ratings: 100836\n",
      "Therefore:  1.6999683055613624 % of the matrix is filled.\n",
      "We have an incredibly sparse matrix to work with here.\n",
      "And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\n",
      "You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\n",
      "One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\n"
     ]
    }
   ],
   "source": [
    "# Movie ID to movie name mapping\n",
    "movie_names = movies_df.set_index('movieId')['title'].to_dict()\n",
    "n_users = len(ratings_df.userId.unique())\n",
    "n_items = len(ratings_df.movieId.unique())\n",
    "print(\"Number of unique users:\", n_users)\n",
    "print(\"Number of unique movies:\", n_items)\n",
    "print(\"The full rating matrix will have:\", n_users*n_items, 'elements.')\n",
    "print('----------')\n",
    "print(\"Number of ratings:\", len(ratings_df))\n",
    "print(\"Therefore: \", len(ratings_df) / (n_users*n_items) * 100, '% of the matrix is filled.')\n",
    "print(\"We have an incredibly sparse matrix to work with here.\")\n",
    "print(\"And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\")\n",
    "print(\"You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\")\n",
    "print(\"One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YnkTvMsCk0tY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jb/.pyenv/versions/3.10.13/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        # create user embeddings\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors) # think of this as a lookup table for the input.\n",
    "        # create item embeddings\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors) # think of this as a lookup table for the input.\n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # matrix multiplication\n",
    "        users, items = data[:,0], data[:,1]\n",
    "        return (self.user_factors(users)*self.item_factors(items)).sum(1)\n",
    "    # def forward(self, user, item):\n",
    "    # \t# matrix multiplication\n",
    "    #     return (self.user_factors(user)*self.item_factors(item)).sum(1)\n",
    "    \n",
    "    def predict(self, user, item):\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LTlGvz7sk0v2"
   },
   "outputs": [],
   "source": [
    "# Creating the dataloader (necessary for PyTorch)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n",
    "\n",
    "# Note: This isn't 'good' practice, in a MLops sense but we'll roll with this since the data is already loaded in memory.\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ratings = ratings_df.copy()\n",
    "        \n",
    "        # Extract all user IDs and movie IDs\n",
    "        users = ratings_df.userId.unique()\n",
    "        movies = ratings_df.movieId.unique()\n",
    "        \n",
    "        #--- Producing new continuous IDs for users and movies ---\n",
    "        \n",
    "        # Unique values : index\n",
    "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
    "        self.movieid2idx = {o:i for i,o in enumerate(movies)}\n",
    "        \n",
    "        # Obtained continuous ID for users and movies\n",
    "        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n",
    "        self.idx2movieid = {i:o for o,i in self.movieid2idx.items()}\n",
    "        \n",
    "        # return the id from the indexed values as noted in the lambda function down below.\n",
    "        self.ratings.movieId = ratings_df.movieId.apply(lambda x: self.movieid2idx[x])\n",
    "        self.ratings.userId = ratings_df.userId.apply(lambda x: self.userid2idx[x])\n",
    "        \n",
    "        \n",
    "        self.x = self.ratings.drop(['rating', 'timestamp'], axis=1).values\n",
    "        self.y = self.ratings['rating'].values\n",
    "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors (ready for torch models.)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6MK3Ymmk0yi",
    "outputId": "50e960e6-ccc7-4852-98cf-55144f7848c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is running on GPU: False\n",
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(610, 8)\n",
      "  (item_factors): Embedding(9724, 8)\n",
      ")\n",
      "user_factors.weight tensor([[0.0428, 0.0268, 0.0330,  ..., 0.0151, 0.0334, 0.0106],\n",
      "        [0.0294, 0.0341, 0.0460,  ..., 0.0303, 0.0438, 0.0119],\n",
      "        [0.0075, 0.0431, 0.0106,  ..., 0.0108, 0.0365, 0.0110],\n",
      "        ...,\n",
      "        [0.0173, 0.0100, 0.0228,  ..., 0.0458, 0.0119, 0.0280],\n",
      "        [0.0444, 0.0149, 0.0333,  ..., 0.0463, 0.0102, 0.0064],\n",
      "        [0.0428, 0.0434, 0.0107,  ..., 0.0262, 0.0187, 0.0074]])\n",
      "item_factors.weight tensor([[0.0258, 0.0321, 0.0448,  ..., 0.0381, 0.0103, 0.0263],\n",
      "        [0.0180, 0.0314, 0.0259,  ..., 0.0058, 0.0464, 0.0389],\n",
      "        [0.0452, 0.0192, 0.0444,  ..., 0.0110, 0.0102, 0.0066],\n",
      "        ...,\n",
      "        [0.0034, 0.0347, 0.0188,  ..., 0.0019, 0.0018, 0.0038],\n",
      "        [0.0473, 0.0427, 0.0008,  ..., 0.0253, 0.0269, 0.0318],\n",
      "        [0.0232, 0.0121, 0.0484,  ..., 0.0037, 0.0217, 0.0384]])\n"
     ]
    }
   ],
   "source": [
    "# num_epochs = 128\n",
    "# cuda = torch.cuda.is_available()\n",
    "num_epochs = 25\n",
    "cuda = False\n",
    "\n",
    "print(\"Is running on GPU:\", cuda)\n",
    "\n",
    "model = MatrixFactorization(n_users, n_items, n_factors=8)\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "# GPU enable if you have a GPU...\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# MSE loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ADAM optimizier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train data\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3c1765cabeaf4d75a130311ddc4591a1",
      "6db170b52f5a4f72afd083a3a9c157aa",
      "69073fd458234bba829af9731b4fce1c",
      "88151edb53134487b95f6bcbcd7fd2b4",
      "9b185906b1dc465e93b9f058a1fec47a",
      "20b4738815cd467dba2946031d6d9027",
      "c279f9a0a0fe498b9db167a237517e6e",
      "005a499c40bd407ca20c2492d9c4f170"
     ]
    },
    "id": "8fIDIdStk000",
    "outputId": "84caf390-d372-4d82-a045-cbf12a9c8cce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:41<16:38, 41.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #0 Loss: 11.0620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [01:03<11:24, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #1 Loss: 4.7463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [01:27<10:04, 27.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #2 Loss: 2.4754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [02:00<10:21, 29.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #3 Loss: 1.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [02:46<11:48, 35.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #4 Loss: 1.3462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [03:48<14:07, 44.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #5 Loss: 1.1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [04:28<12:51, 42.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #6 Loss: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [04:55<10:44, 37.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #7 Loss: 0.8998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [05:17<08:46, 32.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #8 Loss: 0.8369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [05:48<08:05, 32.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #9 Loss: 0.7924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [06:23<07:42, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #10 Loss: 0.7593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [06:48<06:37, 30.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #11 Loss: 0.7347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [07:11<05:40, 28.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #12 Loss: 0.7160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [07:34<04:55, 26.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #13 Loss: 0.7015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [07:58<04:18, 25.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #14 Loss: 0.6904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [08:23<03:50, 25.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #15 Loss: 0.6817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [08:46<03:18, 24.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #16 Loss: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [09:10<02:51, 24.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #17 Loss: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [09:55<03:05, 30.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #18 Loss: 0.6657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [11:10<03:40, 44.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #19 Loss: 0.6627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [11:51<02:52, 43.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #20 Loss: 0.6606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [12:17<01:54, 38.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #21 Loss: 0.6590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [12:31<01:01, 30.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #22 Loss: 0.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [12:49<00:27, 27.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #23 Loss: 0.6570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [13:09<00:00, 31.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #24 Loss: 0.6563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for it in tqdm(range(num_epochs)):\n",
    "#     losses = []\n",
    "#     for x, y in train_loader:\n",
    "#          if cuda:\n",
    "#             x, y = x.cuda(), y.cuda()\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(x)\n",
    "#             loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
    "#             losses.append(loss.item())\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#     print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))\n",
    "\n",
    "for it in tqdm(range(num_epochs)):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "        if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = loss_fn(outputs.squeeze(), y.float())\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"iter #{it} Loss: {sum(losses)/len(losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zs_GVbSYmhib",
    "outputId": "d4a5a7f6-f2a6-4d08-9083-84a2812c3f45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_factors.weight tensor([[1.4145, 1.3358, 1.3360,  ..., 1.3445, 1.3211, 1.2992],\n",
      "        [1.1091, 1.1401, 1.1312,  ..., 1.0894, 1.1001, 1.0945],\n",
      "        [0.7131, 0.7472, 0.6797,  ..., 0.7318, 0.7861, 0.7159],\n",
      "        ...,\n",
      "        [0.9580, 1.0320, 1.1253,  ..., 1.1338, 0.9735, 1.0576],\n",
      "        [1.0130, 0.9789, 0.9884,  ..., 1.0306, 1.0025, 1.0058],\n",
      "        [1.1990, 1.2257, 1.0900,  ..., 1.1690, 1.1126, 1.1602]])\n",
      "item_factors.weight tensor([[0.4547, 0.4400, 0.4715,  ..., 0.4510, 0.4379, 0.4271],\n",
      "        [0.3921, 0.3878, 0.3550,  ..., 0.3461, 0.4029, 0.3875],\n",
      "        [0.4536, 0.4446, 0.4735,  ..., 0.4238, 0.3985, 0.4178],\n",
      "        ...,\n",
      "        [0.3217, 0.3532, 0.3373,  ..., 0.3205, 0.3200, 0.3227],\n",
      "        [0.3962, 0.3918, 0.3496,  ..., 0.3744, 0.3755, 0.3812],\n",
      "        [0.3839, 0.3730, 0.4091,  ..., 0.3646, 0.3822, 0.3996]])\n"
     ]
    }
   ],
   "source": [
    "# By training the model, we will have tuned latent factors for movies and users.\n",
    "c = 0\n",
    "uw = 0\n",
    "iw = 0 \n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        if c == 0:\n",
    "          uw = param.data\n",
    "          c +=1\n",
    "        else:\n",
    "          iw = param.data\n",
    "        #print('param_data', param_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IJgie01_p8k5"
   },
   "outputs": [],
   "source": [
    "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-_tHZ_E_rub",
    "outputId": "cb97ce5d-7140-43fa-8ffa-7603a22eee2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trained_movie_embeddings) # unique movie factor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "bl9s4iqXy75q"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Fit the clusters based on the movie weights\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MDzp-9u-m5n",
    "outputId": "c6f77e4d-68d1-49c5-c022-25e80e99007d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #0\n",
      "\t Waterworld (1995)\n",
      "\t Ace Ventura: When Nature Calls (1995)\n",
      "\t Nutty Professor, The (1996)\n",
      "\t Mission: Impossible II (2000)\n",
      "\t Charlie's Angels (2000)\n",
      "\t Honey, I Shrunk the Kids (1989)\n",
      "\t Lost World: Jurassic Park, The (1997)\n",
      "\t Austin Powers in Goldmember (2002)\n",
      "\t Blair Witch Project, The (1999)\n",
      "\t Casper (1995)\n",
      "Cluster #1\n",
      "\t Pulp Fiction (1994)\n",
      "\t Silence of the Lambs, The (1991)\n",
      "\t Star Wars: Episode IV - A New Hope (1977)\n",
      "\t Braveheart (1995)\n",
      "\t Schindler's List (1993)\n",
      "\t Toy Story (1995)\n",
      "\t American Beauty (1999)\n",
      "\t Seven (a.k.a. Se7en) (1995)\n",
      "\t Lord of the Rings: The Fellowship of the Ring, The (2001)\n",
      "\t Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "Cluster #2\n",
      "\t Jason X (2002)\n",
      "\t When a Stranger Calls (2006)\n",
      "\t Police Academy: Mission to Moscow (1994)\n",
      "\t House Party 2 (1991)\n",
      "\t Amityville II: The Possession (1982)\n",
      "\t Epic Movie (2007)\n",
      "\t Wicker Man, The (2006)\n",
      "\t House of the Dead, The (2003)\n",
      "\t Book of Shadows: Blair Witch 2 (2000)\n",
      "\t Drowning Mona (2000)\n",
      "Cluster #3\n",
      "\t Ace Ventura: Pet Detective (1994)\n",
      "\t Mask, The (1994)\n",
      "\t Stargate (1994)\n",
      "\t Star Wars: Episode I - The Phantom Menace (1999)\n",
      "\t Batman Forever (1995)\n",
      "\t Dumb & Dumber (Dumb and Dumber) (1994)\n",
      "\t Austin Powers: The Spy Who Shagged Me (1999)\n",
      "\t Home Alone (1990)\n",
      "\t Net, The (1995)\n",
      "\t Cliffhanger (1993)\n",
      "Cluster #4\n",
      "\t Three Billboards Outside Ebbing, Missouri (2017)\n",
      "\t Man Bites Dog (C'est arrivé près de chez vous) (1992)\n",
      "\t Incendies (2010)\n",
      "\t Jules and Jim (Jules et Jim) (1961)\n",
      "\t Discreet Charm of the Bourgeoisie, The (Charme discret de la bourgeoisie, Le) (1972)\n",
      "\t Neon Genesis Evangelion: The End of Evangelion (Shin seiki Evangelion Gekijô-ban: Air/Magokoro wo, kimi ni) (1997)\n",
      "\t Trial, The (Procès, Le) (1962)\n",
      "\t Captain Fantastic (2016)\n",
      "\t Last Tango in Paris (Ultimo tango a Parigi) (1972)\n",
      "\t Dune (2000)\n",
      "Cluster #5\n",
      "\t Speed 2: Cruise Control (1997)\n",
      "\t Battlefield Earth (2000)\n",
      "\t Superman IV: The Quest for Peace (1987)\n",
      "\t Karate Kid, Part III, The (1989)\n",
      "\t Dungeons & Dragons (2000)\n",
      "\t Problem Child (1990)\n",
      "\t Flintstones in Viva Rock Vegas, The (2000)\n",
      "\t Stop! Or My Mom Will Shoot (1992)\n",
      "\t Spice World (1997)\n",
      "\t Psycho (1998)\n",
      "Cluster #6\n",
      "\t Jurassic Park (1993)\n",
      "\t Terminator 2: Judgment Day (1991)\n",
      "\t Apollo 13 (1995)\n",
      "\t Aladdin (1992)\n",
      "\t Speed (1994)\n",
      "\t Beauty and the Beast (1991)\n",
      "\t Die Hard: With a Vengeance (1995)\n",
      "\t Groundhog Day (1993)\n",
      "\t X-Men (2000)\n",
      "\t Monsters, Inc. (2001)\n",
      "Cluster #7\n",
      "\t Forrest Gump (1994)\n",
      "\t Shawshank Redemption, The (1994)\n",
      "\t Matrix, The (1999)\n",
      "\t Fight Club (1999)\n",
      "\t Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "\t Usual Suspects, The (1995)\n",
      "\t Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\n",
      "\t Godfather, The (1972)\n",
      "\t Memento (2000)\n",
      "\t Princess Bride, The (1987)\n",
      "Cluster #8\n",
      "\t Independence Day (a.k.a. ID4) (1996)\n",
      "\t Batman (1989)\n",
      "\t True Lies (1994)\n",
      "\t Men in Black (a.k.a. MIB) (1997)\n",
      "\t Mission: Impossible (1996)\n",
      "\t Mrs. Doubtfire (1993)\n",
      "\t Titanic (1997)\n",
      "\t Pretty Woman (1990)\n",
      "\t GoldenEye (1995)\n",
      "\t Twister (1996)\n",
      "Cluster #9\n",
      "\t Coneheads (1993)\n",
      "\t Wild Wild West (1999)\n",
      "\t Flintstones, The (1994)\n",
      "\t Batman & Robin (1997)\n",
      "\t Striptease (1996)\n",
      "\t Hollow Man (2000)\n",
      "\t Showgirls (1995)\n",
      "\t Godzilla (1998)\n",
      "\t I Know What You Did Last Summer (1997)\n",
      "\t Bio-Dome (1996)\n"
     ]
    }
   ],
   "source": [
    "'''It can be seen here that the movies that are in the same cluster tend to have\n",
    "similar genres. Also note that the algorithm is unfamiliar with the movie name\n",
    "and only obtained the relationships by looking at the numbers representing how\n",
    "users have responded to the movie selections.'''\n",
    "for cluster in range(10):\n",
    "    print(\"Cluster #{}\".format(cluster))\n",
    "    movs = []\n",
    "    # Find movie indices belonging to the current cluster\n",
    "    for movidx in np.where(kmeans.labels_ == cluster)[0]:\n",
    "        movid = train_set.idx2movieid[movidx]\n",
    "        # Check how many ratings this movie has\n",
    "        rat_count = len(ratings_df.loc[ratings_df['movieId'] == movid])\n",
    "        movs.append((movie_names[movid], rat_count))\n",
    "    # Sort movies by rating count in descending order and print top 10\n",
    "    for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
    "        print(\"\\t\", mov[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Recommendation_System.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
